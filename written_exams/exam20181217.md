# Exam Questions

## Foundations of HPC, Master in Data Science and Scientific Computing

Mon 17 Dec 2018

### Q1 *[1 point]*: Linking refers to the stage where the binary is put together with the startup procedures and external libraries that have been requested for inclusion.

- [x] True
- [ ] False

### Q2 *[1 point]*: Match the unit of access time with the level of memory hierarchy? (Hint: it is about the relative speeds of each, the answers are not accurate).

- Process Registers - **Cycle (1 nanosecond)**
- L2 Cache - **10 nanoseconds**
- Main Memory - **100 nanoseconds**
- Hard Drive (Swap Space) - **100 milliseconds**

### Q3 *[1 point]*: The compiler flag -O2 stands for which of the following?

- [ ] Disable All Warnings
- [ ] Open the File
- [ ] Turn on Debugging Symbols
- [x] Employ Second Level Optimization

### Q4 *[1 point]*: Which of the following is not a non volatile storage device?

- [x] Random Access Memory
- [ ] Hard Disk
- [ ] Memory Stick
- [ ] NVRAM

### Q5 *[1 point]*: Indicate which of the following is a realistic performance unit for a single socket CPU system.

- [ ] TFLOP/s
- [x] GFLOP/s
- [ ] MFLOP/s
- [ ] none of the above

### Q6 *[1 point]*: Which of the following option can be used to enable multithreaded software?

- [ ] -lblas
- [ ] -O3
- [x] -openmp
- [ ] none of the above

### Q7 *[1 point]*: How vectorization can improve compute performanc?

- [ ] it increases the memory bandwidth
- [x] it increases the capability of number of operations per cycle
- [ ] it increases the clock frequency
- [ ] none of the above

### Q8 *[2 points]*: Given the following HPC storage infrastructure what is the maximum theoretical bandwidth available for a generic parallel filesystem able to write on all the storage areas available:

I/O parallel clients  --> infiniband/network(40gb/sec) ---->  2  I/O storage server , each with  2 RAID5 disk composed by 5 disks (100Mb/sec each) 

- [x] 1600 Mb/sec
- [ ] 800 Mb/sec 
- [ ] 4000 Mb/sec
- [ ] It depends on the number of clients 

### Q9 *[1 point]*: Looking at the following output of the ldd command what of the following statement is FALSE:

```bash
> ldd ./a.out
	linux-vdso.so.1 =>  (0x00007fff3cf2d000)
	libmpi.so.12 => /opt/cluster/openmpi/1.10.2/gnu/4.8.3/lib/libmpi.so.12 (0x00002ae9bdb5e000)
	libpthread.so.0 => /lib64/libpthread.so.0 (0x0000003972800000)
	libc.so.6 => /lib64/libc.so.6 (0x00000038a1a00000)
	libibverbs.so.1 => /usr/lib64/libibverbs.so.1 (0x0000003590400000)
	libopen-rte.so.12 => /opt/cluster/openmpi/1.10.2/gnu/4.8.3/lib/libopen-rte.so.12 (0x00002ae9bde4f000)
	libopen-pal.so.13 => /opt/cluster/openmpi/1.10.2/gnu/4.8.3/lib/libopen-pal.so.13 (0x00002ae9be0ca000)
	libdl.so.2 => /lib64/libdl.so.2 (0x00000038a1e00000)
	librt.so.1 => /lib64/librt.so.1 (0x0000003973400000)
	libm.so.6 => /lib64/libm.so.6 (0x00000038a2600000)
	libutil.so.1 => /lib64/libutil.so.1 (0x00000038a4e00000)
	/lib64/ld-linux-x86-64.so.2 (0x00000038a1600000)
```

- [ ] the code uses dynamic libraries
- [ ] the code is a multithreaded code
- [ ] the code is a parallel code
- [x] the code uses static libraries

### Q10 *[2 points]*: A scientific code in the initialization phase reads an input file of several Gbyte. The time of this initialization phase takes 5% of the overall computation when the code runs in serial. What is the maximum number of cores you may use efficiently in a parallel run on a HPC platform?

- [ ] No more than 4 cores
- [ ] all cores you have on your multicore server that composes your HPC platform
- [x] hard to say without knowing anything about the parallel algorithm implemented
- [ ] hard to say without knowing the cost of the core-hour on the HPC platform

### Q11 *[2 points]*: On an x86_64 system, which of these variables occupies the most memory bytes?

- [x] float *c
- [ ] char a[7] Incorrect
- [ ] short b
- [ ] int b

### Q12 *[2 points]*: How many lines does a direct-mapped cache have in a set, in average?

- [x] 1
- [ ] 8
- [ ] 2
- [ ] 4

### Q13 *[2 points]*: You have been given the task of optimizing (i.e. reduce the time-to-solution) a code, made up of 3 parts:  _A)_, _B)_ and _C)_ - that takes  20%, 30% and 50% of the run time, respectively. Considering the effort that you can allocate on this task, you have the following choices. Which one leads to the best result?

- [ ] speed up part _A)_ by a factor of 4;
- [ ] none of the above;
- [ ] speed up part _A)_ by a factor of 1.5 and part _B)_ by a factor 3;
- [x] speed up part _C)_ by a factor 2.5;

### Q14 *[3 points]*: Consider the following cycle _( `f(i)` returns a value that only depends on `i` )_:

```c
a[0] = f(0);
b[0] = f(0);
c[0] = 0;
for ( i = 1; i < n; i++ )
{
	a[i] = f(i);
	b[i] = a[i-1] * 3;
	c[i] = (a[i-1] / 3) - b[i];
}
```

How would you restructure it so to remove the loop-carried dependency ?

- [ ] with an index change: `j = i+1`
- [x] with an index change `j = i-1`
- [x] none of the answers provided
- [ ] the dependency can not be removed

**Explanation**: The second answer was assuming the index change should have been accompanied by other techniques (loop fission). Without those assumptions, none of the answers is right.

### Q15 *[3 points]*: The following code contains one or more implementation mistakes that generates performance issues:

```c
#include <stdlib.h>
#define SIZE 1024

int main (int arcg, char * argv[]){

  int ** a;
  int i, j;

  a = (int **) malloc( SIZE * sizeof ( int * ) );

  for( i = 0; i < SIZE; i++)
    a[i] = (int *) malloc( SIZE * sizeof ( int * ) );

  for( j = 0; j < SIZE; j++ ){
    for( i = 0; i < SIZE; i++ ){
      a[ j ] [ i ]= i * SIZE;
    }

    return 0;
  }
}
```

- [x] Avoid to use malloc in a loop: `a = (int *) malloc( SIZE * SIZE * sizeof ( int ) );`.
- [ ] Optimize the loop  for Cache and Vectorization: `for( i = 0; i < SIZE * SIZE; i++ ){ a[ i ]= i * SIZE; }`.
- [x] both of the above
- [ ] none of the above

**Explanation**: The original answer was the third one, but since the second one was providing different results the first one was also valid.

### Q16 *[3 points]*: Consider the two following codes that evaluate a polynomial of degree n `a_0 + a_1*x + a_2*x^2 + ... + a_n*x^n`. The first one is the naive, straightforward implementation, while the second one is the smarter Horner's algorithm. Which statement is correct?

```c
// note: a[] is the array that holds the coefficients; it has n+1 elements, running from 0 to n
double evaluate_poly_naive( double a[], double x, double n)
{
	double res = a[0]; 
    double x_pwr = x;  
    for ( int i = 1; i <= n; i++ )
    {
      	res   += a[i] * x_pwr;
        x_pwr *= x;
    }
    
    return res;
}
double evaluate_poly_Horner( double a[], double x, double n )
{
    double res = a[n];
    for ( int i = n-1; i >= 0; i-- )
        res += a[i] * res * x;
    
    return res;
}
```

- [x] none of the answers provided
- [x] `poly_naive` is faster because it requires less cycles per element
- [ ] both of the answers provided
- [ ] `poly_Horner` is faster because it involves less operations

**Explanation**: `poly_naive` is optimal on modern CPUs (no further explanation provided because Tornatore was missing). Since it returns a wrong result when one term is 0 in the product, the first answer was also considered good.

### Q17 *[1 point]*: Which bandwidth (in Gigabyte/sec) do you expect to measure between two HPC nodes both equipped with QDR Infiniband network?

- [ ] at least 4 GB/sec
- [ ] at most 5 GB/sec
- [ ] around 3.2 GB/sec
- [x] at most 4 GB/sec

**Explanation:** We were assuming a standard QDR with 4 lanes, for a total bandwidth of 40 Gbits/s = 5 GBytes/s. Since 2/10 of the bits are used for parity, the actual bandwidth is 4 GB/sec, even though real bandwidth observed in class was around 3.2 GB/sec.

### Q18 *[1 point]*: On your cluster you issued the following command to check the status of jobs. Which statement is true?

```bash
[exact@master ~]$ qstat -a
master:
                                                            Req'd  Req'd   Elap
Job ID          Username Queue    Jobname    SessID NDS TSK Memory Time  S Time
--------------- -------- -------- ---------- ------ --- --- ------ ----- - -----
60280.master    XXXXXXX  YYYY     xxxxxxxx      --    1  64    --  01:00 Q   --
60516.master    AAAAAAA  ZZZZ     xxxxxxxx    47894   1  24    --  12:00 R 03:39
60537.master    BBBBBBB  ZZZZ     yyyyyyyy      --    4  92    --  24:00 Q   --
60538.master    CCCCCCC  KKKK     xxxxxx.sh   52542   4  16    --  96:00 R 00:00
60539.master    DDDDDDD  KKKK     yyyyyy.sh   52606   4  12    --  96:00 R 00:00
60540.master    DDDDDDD  KKKK     xxxxxx.sh     --    8  24    --  96:00 Q   --
60541.master    DDDDDDD  KKKK     zzzzzz.sh   52851   1   3    --  96:00 R 00:00
```

- [ ] Queue ZZZZ  could  execute now a job requesting 8 nodes  
- [x] User XXXXXXX' job is waiting because at the moment no nodes are available with at least 64 processors
- [ ] The local resource manager is no longer able to accept jobs
- [ ] There are at least  8 nodes with 24 cores available right now

### Q19 *[2 points]*: You need to buy computing hours to run some  large simulations with your embarrassingly parallel code. Which is your choice among the following options, (We assume that for all systems the frequency of the processor is the same and the total number of cores is 2048)?

- [ ] An infiniband cluster based on quad socket nodes with 64 cores per node: cost per core-hours of 0.10 cents
- [ ] A Gigabit cluster based on quad socket nodes with 64 cores per nodes; cost per hours 0.08 cents
- [ ] An infiniband cluster based on dual socket nodes with 32 cores per node: cost per core-hours of 0.10 cents
- [x] A Gigabit cluster based on dual socket nodes with 16 cores per nodes; cost per hours 0.05 cents

**Explanation:** Embarassingly parallel means not many communications between nodes, so we disregard network speed and focus on the cheapest cost per core hour.

### Q20 *[2 points]*: On one node of your cluster you have user XXXXX that runs  a parallel program aaaa. Using top you observe this. What is XXXXX's aaaa application likely doing?

```bash
top - 19:09:23 up 60 days,  6:44,  1 user,  load average: 8.14, 8.34, 8.50
Tasks: 787 total,   3 running, 784 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.2 us,  4.9 sy,  0.0 ni, 91.0 id,  3.6 wa,  0.0 hi,  0.2 si,  0.0 st
KiB Mem : 65754220 total, 59117108 free,  2265384 used,  4371728 buff/cache
KiB Swap:  8388604 total,  7193956 free,  1194648 used. 62963332 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 81342 XXXXXXXX  20   0 3527312 1.043g   8132 D   3.6  1.7   1:02.66 aaaa
 81338 XXXXXXXX  20   0 3527320 1.043g   8120 D   3.3  1.7   0:16.57 aaaa
 81340 XXXXXXXX  20   0 3527312 1.041g   8128 D   3.3  1.7   1:01.68 aaaa
 81343 XXXXXXXX  20   0 3527248 1.041g   8140 D   3.3  1.7   1:01.31 aaaa
 81339 XXXXXXXX  20   0 3527248 1.043g   8004 D   2.6  1.7   1:02.20 aaaa
 81341 XXXXXXXX  20   0 3527248 1.043g   8004 D   2.6  1.7   0:59.79 aaaa
 81345 XXXXXXXX  20   0 3527312 1.041g   8128 D   2.6  1.7   1:02.86 aaaa
 81346 XXXXXXXX  20   0 3527248 1.043g   8000 D   2.6  1.7   0:58.11 aaaa
```

- [x] it is not doing well but we cannot  understand what's wrong 
- [ ] It is crunching numbers as crazy 
- [x] it is writing and or reading tons of data  
- [ ] It is  swapping (capital sin !)

**Explanation:** The right answer was the third one, but since we didn't have a practical way to know that it was doing I/O the first one was also considered partly correct.

### Q21 *[1 point]*: If you have to write a 1 GB file which is the best option?

- [ ] use Parallel FS
- [x] use local FS
- [ ] use usb-disk
- [ ] use NFS

**No explanation was provided on this one.**

### Q22 *[1 point]*: What is a cache hierarchy ?

- [ ] A specific hardware to provide cache-coherency among processors  
- [ ] a software technique to increase data locality 
- [ ] The use of different types of caches on different sockets 
- [x] a series of connected CPU caches in order to provide fast access to data in RAM